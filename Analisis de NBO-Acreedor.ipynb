{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(dataset,columns):\n",
    "    \n",
    "    for column in columns:\n",
    "        dummy=pd.get_dummies(dataset[column],prefix=column)\n",
    "\n",
    "        dataset=dataset.drop(column,axis=1)#axis=1-->para eliminar columna y no fila\n",
    "\n",
    "        dataset=pd.concat([dataset,dummy],axis=1)#axis=1-->para agregar columna y no fila\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(dataset,columns):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaled_X = scaler.fit_transform(dataset[columns])\n",
    "    \n",
    "    X_normalized=pd.DataFrame(scaled_X,columns=columns)\n",
    "    \n",
    "    dataset=dataset.drop(columns,axis=1)#axis=1-->para eliminar columna y no fila\n",
    "    \n",
    "    new_dataset=pd.concat([dataset,X_normalized],axis=1)#axis=1-->para agregar columna y no fila\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de filas de este dataset es de:30069\n",
      "(30069, 11)\n",
      "id               object\n",
      "Macro_sector     object\n",
      "Sector           object\n",
      "Subsector        object\n",
      "Actividad        object\n",
      "Ventas          float64\n",
      "Activo_fijo     float64\n",
      "Potencial       float64\n",
      "Cheques          object\n",
      "Etapa            object\n",
      "Producto         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn=pymysql.connect(host='localhost', user='root', passwd='', db='unifin')\n",
    "    cur=conn.cursor()\n",
    "    query=\"SELECT Id_cliente,Macro_sector,Sector,Subsector,Actividad,Ventas,Activo_fijo,Potencial,Cheques,Etapa,Producto from nbo_model;\"\n",
    "    cur.execute(query)\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "except pymysql.Error as e:\n",
    "    msj= (\"Error %d: %s\" % (e.args[0], e.args[1]))\n",
    "    print(msj)\n",
    "else:\n",
    "    headers=['id','Macro_sector','Sector','Subsector','Actividad','Ventas','Activo_fijo','Potencial','Cheques','Etapa','Producto']\n",
    "    dataset_dummy={}\n",
    "    filas=0\n",
    "\n",
    "    for h in headers:\n",
    "        dataset_dummy[h]=[]\n",
    "\n",
    "    if(len(res)>0):\n",
    "        for r in res:\n",
    "            filas+=1\n",
    "            for i in range(len(headers)):\n",
    "                dataset_dummy[headers[i]].append(r[i])\n",
    "\n",
    "    print('El numero de filas de este dataset es de:'+str(filas))\n",
    "\n",
    "    df1=pd.DataFrame(dataset_dummy) \n",
    "    print(df1.shape)\n",
    "\n",
    "    print(df1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=create_dummies(df1,['Etapa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30069, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=df2[['Etapa_R']]\n",
    "X=df2[['Macro_sector','Sector','Subsector','Actividad','Ventas','Activo_fijo','Potencial']]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X['Cheques']=X['Cheques'].fillna(0)\n",
    "indexes_empties=X[pd.isnull(X).any(axis=1)].index.tolist()\n",
    "X=X.dropna(axis=0,how=\"any\")\n",
    "X= X.reset_index(drop=True)\n",
    "Y=Y.drop(indexes_empties)\n",
    "Y= Y.reset_index(drop=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized=normalize_columns(X,['Ventas','Activo_fijo','Potencial'])\n",
    "X_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 1020)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized=create_dummies(X_normalized,['Macro_sector','Sector','Subsector','Actividad'])\n",
    "X_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X_normalized,Y.values.ravel(),test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        CL\n",
       "1        CL\n",
       "2         P\n",
       "3        CL\n",
       "4         P\n",
       "5         R\n",
       "6        CL\n",
       "7        CL\n",
       "8         R\n",
       "9        CL\n",
       "10       CL\n",
       "11       CL\n",
       "12        R\n",
       "13        P\n",
       "14       CL\n",
       "15        P\n",
       "16       CL\n",
       "17       CL\n",
       "18       CL\n",
       "19       CL\n",
       "20       CL\n",
       "21       CL\n",
       "22       CL\n",
       "23       CL\n",
       "24       CL\n",
       "25       CL\n",
       "26       CL\n",
       "27        P\n",
       "28       CL\n",
       "29       CL\n",
       "         ..\n",
       "30039    CL\n",
       "30040    CL\n",
       "30041    CL\n",
       "30042    CL\n",
       "30043     P\n",
       "30044     P\n",
       "30045    CL\n",
       "30046    CL\n",
       "30047     R\n",
       "30048    CL\n",
       "30049    CL\n",
       "30050    CL\n",
       "30051    CL\n",
       "30052    CL\n",
       "30053     P\n",
       "30054    CL\n",
       "30055     R\n",
       "30056    CL\n",
       "30057    CL\n",
       "30058    CL\n",
       "30059     R\n",
       "30060    CL\n",
       "30061    CL\n",
       "30062    CL\n",
       "30063    CL\n",
       "30064     P\n",
       "30065    CL\n",
       "30066    CL\n",
       "30067    CL\n",
       "30068    CL\n",
       "Name: Etapa, Length: 30069, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Etapa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,Y_train)\n",
    "\n",
    "scorel=lr.score(X_test,Y_test)\n",
    "\n",
    "predictl=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jess/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 112 ms, total: 3.27 s\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest=RandomForestClassifier(n_jobs=2)\n",
    "\n",
    "forest.fit(X_train,Y_train)\n",
    "\n",
    "scoref=forest.score(X_test,Y_test)\n",
    "\n",
    "predictf=forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 30s, sys: 292 ms, total: 5min 31s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "C=1e3\n",
    "svc_rbf = SVC(kernel=\"rbf\", C=C, gamma=0.1) #kernel radial\n",
    "\n",
    "model= svc_rbf.fit(X_train,Y_train)\n",
    "\n",
    "scores=model.score(X_test,Y_test)\n",
    "\n",
    "predicts=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 168 ms, total: 3min\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "scorek=knn.score(X_test,Y_test)\n",
    "\n",
    "predictknn=knn.predict(X_test)\n",
    "\n",
    "#predictknn2=knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> LR.... <<\n",
      "Score 0.844525912347942\n",
      "5068 Registros acertados de 6001\n",
      "2 \"unos\" de 929 --> 0.21528525296017223 %\n",
      "5066 \"zeros\" de 5072 --> 99.88170347003154 %\n",
      "..................\n",
      "\n",
      ">> Forest.... <<\n",
      "Score 0.8413597733711048\n",
      "5049 Registros acertados de 6001\n",
      "8 \"unos\" de 929 --> 0.8611410118406889 %\n",
      "5041 \"zeros\" de 5072 --> 99.38880126182966 %\n",
      "..................\n",
      "\n",
      ">> SVR.... <<\n",
      "Score 0.8425262456257291\n",
      "5056 Registros acertados de 6001\n",
      "6 \"unos\" de 929 --> 0.6458557588805167 %\n",
      "5050 \"zeros\" de 5072 --> 99.56624605678233 %\n",
      "..................\n",
      "\n",
      ">> KNN.... <<\n",
      "Score 0.8298616897183803\n",
      "4980 Registros acertados de 6001\n",
      "141 \"unos\" de 929 --> 15.177610333692142 %\n",
      "4839 \"zeros\" de 5072 --> 95.40615141955836 %\n",
      "..................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contone=0\n",
    "contzero=0\n",
    "total=len(Y_test)\n",
    "\n",
    "for i in Y_test:\n",
    "    if(i==1):\n",
    "        contone=contone+1\n",
    "    else:\n",
    "        contzero=contzero+1        \n",
    "\n",
    "#----------------------------\n",
    "\n",
    "print('>> LR.... <<')\n",
    "print('Score',scorel)\n",
    "\n",
    "c=0\n",
    "cont=0\n",
    "cont2=0\n",
    "for a, b in zip(predictl, Y_test):\n",
    "    if (a == b):\n",
    "        c=c+1\n",
    "        if(a==1):\n",
    "            cont=cont+1\n",
    "        else:\n",
    "            cont2=cont2+1\n",
    "print(c,'Registros acertados de',total )\n",
    "print(cont,'\"unos\" de',contone,'-->',((cont*100)/contone),'%') \n",
    "print(cont2,'\"zeros\" de',contzero,'-->',((cont2*100)/contzero),'%')\n",
    "print('..................')\n",
    "print()\n",
    "  \n",
    "#----------------------------\n",
    "\n",
    "print('>> Forest.... <<')\n",
    "print('Score',scoref)\n",
    "\n",
    "c=0\n",
    "cont=0\n",
    "cont2=0\n",
    "for a, b in zip(predictf, Y_test):\n",
    "    if (a == b):\n",
    "        c=c+1\n",
    "        if(a==1):\n",
    "            cont=cont+1\n",
    "        else:\n",
    "            cont2=cont2+1\n",
    "print(c,'Registros acertados de',total )\n",
    "print(cont,'\"unos\" de',contone,'-->',((cont*100)/contone),'%') \n",
    "print(cont2,'\"zeros\" de',contzero,'-->',((cont2*100)/contzero),'%')\n",
    "print('..................')\n",
    "print()\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "print('>> SVR.... <<')\n",
    "print('Score',scores)\n",
    "\n",
    "c=0\n",
    "cont=0\n",
    "cont2=0\n",
    "for a, b in zip(predicts, Y_test):\n",
    "    if (a == b):\n",
    "        c=c+1\n",
    "        if(a==1):\n",
    "            cont=cont+1\n",
    "        else:\n",
    "            cont2=cont2+1\n",
    "print(c,'Registros acertados de',total )\n",
    "print(cont,'\"unos\" de',contone,'-->',((cont*100)/contone),'%') \n",
    "print(cont2,'\"zeros\" de',contzero,'-->',((cont2*100)/contzero),'%')\n",
    "print('..................')\n",
    "print()\n",
    "  \n",
    "#----------------------------\n",
    "\n",
    "print('>> KNN.... <<')\n",
    "print('Score',scorek)\n",
    "\n",
    "c=0\n",
    "cont=0\n",
    "cont2=0\n",
    "for a, b in zip(predictknn, Y_test):\n",
    "    if (a == b):\n",
    "        c=c+1\n",
    "        if(a==1):\n",
    "            cont=cont+1\n",
    "        else:\n",
    "            cont2=cont2+1\n",
    "print(c,'Registros acertados de',total )\n",
    "print(cont,'\"unos\" de',contone,'-->',((cont*100)/contone),'%') \n",
    "print(cont2,'\"zeros\" de',contzero,'-->',((cont2*100)/contzero),'%')\n",
    "print('..................')\n",
    "print()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener mejores variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 15s, sys: 2min 27s, total: 18min 42s\n",
      "Wall time: 12min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression()    \n",
    "rfe=RFECV(lr)\n",
    "rfe.fit(X_normalized,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Actividad_8123078', 'Actividad_8944098', 'Actividad_9411018']\n"
     ]
    }
   ],
   "source": [
    "best_variables=[]\n",
    "\n",
    "for a, b in zip(X_normalized.columns.values.tolist(), rfe.support_):\n",
    "    if (b==True):\n",
    "        best_variables.append(a)\n",
    "        \n",
    "print(best_variables)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'acreedor2.sav'\n",
    "pickle.dump(knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'acreedor2_knn_avar.sav'\n",
    "\n",
    "knn = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "scorek=knn.score(X_test,Y_test)\n",
    "\n",
    "predictknn=knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss=knn.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictknnctknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       ...,\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.4, 0. , ..., 0.2, 0.8, 0. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> KNN.... <<\n",
      "Score 0.8360273287785369\n",
      "5017 Registros acertados de 6001\n",
      "145 \"unos\" de 924 --> 15.692640692640692 %\n",
      "4872 \"zeros\" de 5077 --> 95.96218239117589 %\n",
      "..................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contone=0\n",
    "contzero=0\n",
    "total=len(Y_test)\n",
    "\n",
    "for i in Y_test:\n",
    "    if(i==1):\n",
    "        contone=contone+1\n",
    "    else:\n",
    "        contzero=contzero+1        \n",
    "\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "print('>> KNN.... <<')\n",
    "print('Score',scorek)\n",
    "\n",
    "c=0\n",
    "cont=0\n",
    "cont2=0\n",
    "for a, b in zip(predictknn, Y_test):\n",
    "    if (a == b):\n",
    "        c=c+1\n",
    "        if(a==1):\n",
    "            cont=cont+1\n",
    "        else:\n",
    "            cont2=cont2+1\n",
    "print(c,'Registros acertados de',total )\n",
    "print(cont,'\"unos\" de',contone,'-->',((cont*100)/contone),'%') \n",
    "print(cont2,'\"zeros\" de',contzero,'-->',((cont2*100)/contzero),'%')\n",
    "print('..................')\n",
    "print()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
